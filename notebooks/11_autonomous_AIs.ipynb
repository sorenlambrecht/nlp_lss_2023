{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOTHtNQKq+lDs9K6S277z0R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Autonomous AI\n","In this notebook, we are going to unwrap an LLM-based autonomous agent: BabyAGI. You will see why it is called an \"AGI\": by giving a vague task objective with some tools (to access internet, do math etc.), BabyAGI can conduct the task for you without tedious prompt engineering :)\n","\n","Here we use the BabyAGI implemented by [LangChain](https://python.langchain.com/en/latest/index.html), a mostly-used python package for LLM applications.\n","\n","We will first witness the magic of BabyAGI, then open it to learn its mechanism."],"metadata":{"id":"lZxPq9HXUP9w"}},{"cell_type":"markdown","source":["### Package installment\n"],"metadata":{"id":"LcfUzWefZN8g"}},{"cell_type":"code","source":["#!pip install langchain faiss-cpu pydantic openai"],"metadata":{"id":"5LetJo0NcXHH","executionInfo":{"status":"ok","timestamp":1684759165975,"user_tz":-120,"elapsed":244,"user":{"displayName":"Jingwei Ni","userId":"14293482943107053262"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import os\n","from collections import deque\n","from typing import Dict, List, Optional, Any\n","\n","from langchain import LLMChain, OpenAI, PromptTemplate\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.llms import BaseLLM\n","from langchain.vectorstores.base import VectorStore\n","from pydantic import BaseModel, Field\n","from langchain.chains.base import Chain\n","from langchain.experimental import BabyAGI"],"metadata":{"id":"t_ayYHWZgVhK","executionInfo":{"status":"ok","timestamp":1684759985098,"user_tz":-120,"elapsed":258,"user":{"displayName":"Jingwei Ni","userId":"14293482943107053262"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["### Set Your OpenAI Key\n","\n","A natural question: why aren't autonomous agents like BabyAGI and AutoGPT widely used by all kinds of applications? One explanation is that these agents usually require multiple-step reasoning/reflection using LLMs, which requires LLMs read long contexts and generate long outputs. This is EXPENSIVE!\n","\n","But definitely, this is the future, where instruction-following LLMs are becoming smaller and open-sourced (e.g., Vicuna)"],"metadata":{"id":"FQc5mikacYwn"}},{"cell_type":"code","source":["os.environ[\"OPENAI_API_KEY\"] = \"sk-xxx\""],"metadata":{"id":"rickzghYcexe","executionInfo":{"status":"ok","timestamp":1684759169640,"user_tz":-120,"elapsed":3,"user":{"displayName":"Jingwei Ni","userId":"14293482943107053262"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Connect to the Vector Store"],"metadata":{"id":"FXrQsbKKZ3-Y"}},{"cell_type":"markdown","source":["FAISS contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM."],"metadata":{"id":"92cHePpCZ1tJ"}},{"cell_type":"code","source":["# Here we use FAISS, a library for efficient similarity search and clustering of dense vectors. \n","from langchain.vectorstores import FAISS\n","from langchain.docstore import InMemoryDocstore\n","from langchain.embeddings import OpenAIEmbeddings"],"metadata":{"id":"4-mcAdhffd9G","executionInfo":{"status":"ok","timestamp":1684759988815,"user_tz":-120,"elapsed":2,"user":{"displayName":"Jingwei Ni","userId":"14293482943107053262"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Define your embedding model\n","embeddings_model = OpenAIEmbeddings()\n","# Initialize the vectorstore as empty\n","import faiss\n","\n","embedding_size = 1536 # the embedding size of OpenAIEmbedding: text-embedding-ada-002\n","index = faiss.IndexFlatL2(embedding_size)\n","vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"],"metadata":{"id":"KiXobimsZ9EH","executionInfo":{"status":"ok","timestamp":1684759170679,"user_tz":-120,"elapsed":2,"user":{"displayName":"Jingwei Ni","userId":"14293482943107053262"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### Define the Chains\n","BabyAGI relies on three LLM chains:\n","\n","- Task creation chain to select new tasks to add to the list\n","\n","- Task prioritization chain to re-prioritize tasks\n","\n","- Execution Chain to execute the tasks"],"metadata":{"id":"ZknnZN3AgoQ2"}},{"cell_type":"markdown","source":["##### What are Chains in LangChain?\n","Chains allow us to combine multiple components together to create a single, coherent application. For example, we can create a chain that takes user input, formats it with a PromptTemplate, and then passes the formatted response to an LLM. We can build more complex chains by combining multiple chains together, or by combining chains with other components."],"metadata":{"id":"PKlqQ1ZYmaAm"}},{"cell_type":"code","source":["llm = OpenAI(temperature=0.9)\n","prompt = PromptTemplate(\n","    input_variables=[\"product\"],\n","    template=\"What is a good name for a company that makes {product}?\",\n",")\n","\n","chain = LLMChain(llm=llm, prompt=prompt)\n","\n","# Run the chain only specifying the input variable.\n","print(chain.run(\"colorful socks\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5ZZ_rXqmuSm","executionInfo":{"status":"ok","timestamp":1684761421776,"user_tz":-120,"elapsed":630,"user":{"displayName":"Jingwei Ni","userId":"14293482943107053262"}},"outputId":"b87b906a-6778-4ad8-b2ce-3e46b1eb444c"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Colorful Toes.\n"]}]},{"cell_type":"code","source":["from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n","from langchain import OpenAI, GoogleSearchAPIWrapper, LLMChain\n","\n","GOOGLE_API_KEY = \"xxx\" # you can get one at https://developers.google.com/custom-search/v1/overview\n","GOOGLE_CSE_ID = \"xxx\" # you can get one at cse.google.com\n","\n","todo_prompt = PromptTemplate.from_template(\n","    \"You are a planner who is an expert at coming up with a todo list for a given objective. Come up with a todo list for this objective: {objective}\"\n",")\n","todo_chain = LLMChain(llm=OpenAI(temperature=0), prompt=todo_prompt)\n","search = GoogleSearchAPIWrapper(google_api_key=GOOGLE_API_KEY, google_cse_id=GOOGLE_CSE_ID)\n","tools = [\n","    Tool(\n","        name=\"Search\",\n","        func=search.run,\n","        description=\"useful for when you need to answer questions about current events\",\n","    ),\n","    Tool(\n","        name=\"TODO\",\n","        func=todo_chain.run,\n","        description=\"useful for when you need to come up with todo lists. Input: an objective to create a todo list for. Output: a todo list for that objective. Please be very clear what the objective is!\",\n","    ),\n","] # more tools at https://python.langchain.com/en/latest/modules/agents/tools/getting_started.html\n","\n","# ZeroShotAgent: a simple agent that choose a tool to conduct one task.\n","prefix = \"\"\"You are an AI who performs one task based on the following objective: {objective}. Take into account these previously completed tasks: {context}.\"\"\"\n","suffix = \"\"\"Question: {task}\n","{agent_scratchpad}\"\"\"\n","prompt = ZeroShotAgent.create_prompt(\n","    tools,\n","    prefix=prefix,\n","    suffix=suffix,\n","    input_variables=[\"objective\", \"task\", \"context\", \"agent_scratchpad\"],\n",")"],"metadata":{"id":"XLZtBNW3g071","executionInfo":{"status":"ok","timestamp":1684760725477,"user_tz":-120,"elapsed":1034,"user":{"displayName":"Jingwei Ni","userId":"14293482943107053262"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["llm = OpenAI(temperature=0) # an text-davinci-003 is loaded (i.e., GPT-3.5)\n","llm_chain = LLMChain(llm=llm, prompt=prompt)\n","tool_names = [tool.name for tool in tools]\n","agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names)\n","agent_executor = AgentExecutor.from_agent_and_tools(\n","    agent=agent, tools=tools, verbose=True\n",")"],"metadata":{"id":"MKb_8a4Jg9Ui","executionInfo":{"status":"ok","timestamp":1684760729994,"user_tz":-120,"elapsed":2,"user":{"displayName":"Jingwei Ni","userId":"14293482943107053262"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["### Run BabyAGI"],"metadata":{"id":"cX8WtnRYaM8r"}},{"cell_type":"code","source":["\n","OBJECTIVE = \"Write a weather report for Zurich today\"\n","\n","# Logging of LLMChains\n","verbose = False\n","# If None, will keep on going forever\n","max_iterations: Optional[int] = 3\n","baby_agi = BabyAGI.from_llm(\n","    llm=llm, vectorstore=vectorstore, verbose=verbose, max_iterations=max_iterations\n",")"],"metadata":{"id":"cceiTiv9aO8K","executionInfo":{"status":"ok","timestamp":1684760732502,"user_tz":-120,"elapsed":221,"user":{"displayName":"Jingwei Ni","userId":"14293482943107053262"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["baby_agi({\"objective\": OBJECTIVE})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BiJqM5XqeBvn","executionInfo":{"status":"ok","timestamp":1684760785289,"user_tz":-120,"elapsed":38723,"user":{"displayName":"Jingwei Ni","userId":"14293482943107053262"}},"outputId":"cbc49e30-3acd-4abd-c4a8-0082ab922008"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[95m\u001b[1m\n","*****TASK LIST*****\n","\u001b[0m\u001b[0m\n","1: Make a todo list\n","\u001b[92m\u001b[1m\n","*****NEXT TASK*****\n","\u001b[0m\u001b[0m\n","1: Make a todo list\n","\u001b[93m\u001b[1m\n","*****TASK RESULT*****\n","\u001b[0m\u001b[0m\n","\n","\n","1. Gather temperature data for Zurich from the past 24 hours\n","2. Gather humidity data for Zurich from the past 24 hours\n","3. Analyze temperature and humidity data to determine current weather conditions in Zurich\n","4. Write a weather report for Zurich based on the data analysis\n","\u001b[95m\u001b[1m\n","*****TASK LIST*****\n","\u001b[0m\u001b[0m\n","2: Analyze temperature and humidity data to determine current weather conditions in Zurich\n","3: Create a visual representation of the temperature and humidity data for Zurich\n","4: Compare the current weather conditions in Zurich to the forecasted weather conditions\n","5: Identify any potential weather-related hazards in Zurich\n","6: Make recommendations for any necessary precautions based on the weather conditions in Zurich\n","7: Collect temperature data for Zurich from the past 24 hours\n","8: Collect humidity data for Zurich from the past 24 hours\n","\u001b[92m\u001b[1m\n","*****NEXT TASK*****\n","\u001b[0m\u001b[0m\n","2: Analyze temperature and humidity data to determine current weather conditions in Zurich\n","\u001b[93m\u001b[1m\n","*****TASK RESULT*****\n","\u001b[0m\u001b[0m\n","\n","\n","The current weather conditions in Zurich are mild. The temperature in the past 24 hours has been between 10 and 15 degrees Celsius, with an average temperature of 12 degrees Celsius. The humidity in the past 24 hours has been between 40 and 60%, with an average humidity of 50%. Overall, the weather in Zurich is pleasant and comfortable.\n","\u001b[95m\u001b[1m\n","*****TASK LIST*****\n","\u001b[0m\u001b[0m\n","3: Collect temperature data for Zurich from the past 24 hours\n","4: Collect humidity data for Zurich from the past 24 hours\n","5: Analyze the temperature and humidity data to determine the trend in weather conditions in Zurich over the past 24 hours\n","6: Compare the current weather conditions in Zurich to the weather conditions in other cities in Switzerland\n","7: Identify any potential weather-related events that may occur in Zurich in the near future\n","8: Make recommendations for any necessary precautions based on the forecasted weather conditions in Zurich\n","9: Collect temperature data for Zurich from the past week\n","10: Collect humidity data for Zurich from the past week\n","11: Create a visual representation of the temperature and humidity data for Zurich\n","\u001b[92m\u001b[1m\n","*****NEXT TASK*****\n","\u001b[0m\u001b[0m\n","3: Collect temperature data for Zurich from the past 24 hours\n","\u001b[93m\u001b[1m\n","*****TASK RESULT*****\n","\u001b[0m\u001b[0m\n","\n","\n","I have collected temperature data for Zurich from the past 24 hours. The temperature has ranged from a low of 4°C to a high of 12°C. The average temperature for the past 24 hours has been 8°C.\n","\u001b[91m\u001b[1m\n","*****TASK ENDING*****\n","\u001b[0m\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'objective': 'Write a weather report for Zurich today'}"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["### What is inside BabyAGI?\n","\n",">![BabyAGI](https://user-images.githubusercontent.com/21254008/235015461-543a897f-70cc-4b63-941a-2ae3c9172b11.png)"],"metadata":{"id":"OySLbcgXn8Be"}},{"cell_type":"code","source":["class BabyAGI(Chain, BaseModel):\n","    \"\"\"Controller model for the BabyAGI agent.\"\"\"\n","\n","    task_list: deque = Field(default_factory=deque)\n","    task_creation_chain: Chain = Field(...)\n","    task_prioritization_chain: Chain = Field(...)\n","    execution_chain: Chain = Field(...)\n","    task_id_counter: int = Field(1)\n","    vectorstore: VectorStore = Field(init=False)\n","    max_iterations: Optional[int] = None\n","\n","    class Config:\n","        \"\"\"Configuration for this pydantic object.\"\"\"\n","\n","        arbitrary_types_allowed = True\n","\n","    def add_task(self, task: Dict) -> None:\n","        self.task_list.append(task)\n","\n","    def print_task_list(self) -> None:\n","        print(\"\\033[95m\\033[1m\" + \"\\n*****TASK LIST*****\\n\" + \"\\033[0m\\033[0m\")\n","        for t in self.task_list:\n","            print(str(t[\"task_id\"]) + \": \" + t[\"task_name\"])\n","\n","    def print_next_task(self, task: Dict) -> None:\n","        print(\"\\033[92m\\033[1m\" + \"\\n*****NEXT TASK*****\\n\" + \"\\033[0m\\033[0m\")\n","        print(str(task[\"task_id\"]) + \": \" + task[\"task_name\"])\n","\n","    def print_task_result(self, result: str) -> None:\n","        print(\"\\033[93m\\033[1m\" + \"\\n*****TASK RESULT*****\\n\" + \"\\033[0m\\033[0m\")\n","        print(result)\n","\n","    @property\n","    def input_keys(self) -> List[str]:\n","        return [\"objective\"]\n","\n","    @property\n","    def output_keys(self) -> List[str]:\n","        return []\n","\n","    def get_next_task(\n","        self, result: str, task_description: str, objective: str\n","    ) -> List[Dict]:\n","        \"\"\"Get the next task.\"\"\"\n","        task_names = [t[\"task_name\"] for t in self.task_list]\n","\n","        incomplete_tasks = \", \".join(task_names)\n","        response = self.task_creation_chain.run(\n","            result=result,\n","            task_description=task_description,\n","            incomplete_tasks=incomplete_tasks,\n","            objective=objective,\n","        )\n","        new_tasks = response.split(\"\\n\")\n","        return [\n","            {\"task_name\": task_name} for task_name in new_tasks if task_name.strip()\n","        ]\n","\n","    def prioritize_tasks(self, this_task_id: int, objective: str) -> List[Dict]:\n","        \"\"\"Prioritize tasks.\"\"\"\n","        task_names = [t[\"task_name\"] for t in list(self.task_list)]\n","        next_task_id = int(this_task_id) + 1\n","        response = self.task_prioritization_chain.run(\n","            task_names=\", \".join(task_names),\n","            next_task_id=str(next_task_id),\n","            objective=objective,\n","        )\n","        new_tasks = response.split(\"\\n\")\n","        prioritized_task_list = []\n","        for task_string in new_tasks:\n","            if not task_string.strip():\n","                continue\n","            task_parts = task_string.strip().split(\".\", 1)\n","            if len(task_parts) == 2:\n","                task_id = task_parts[0].strip()\n","                task_name = task_parts[1].strip()\n","                prioritized_task_list.append(\n","                    {\"task_id\": task_id, \"task_name\": task_name}\n","                )\n","        return prioritized_task_list\n","\n","    def _get_top_tasks(self, query: str, k: int) -> List[str]:\n","        \"\"\"Get the top k tasks based on the query.\"\"\"\n","        results = self.vectorstore.similarity_search(query, k=k)\n","        if not results:\n","            return []\n","        return [str(item.metadata[\"task\"]) for item in results]\n","\n","    def execute_task(self, objective: str, task: str, k: int = 5) -> str:\n","        \"\"\"Execute a task.\"\"\"\n","        context = self._get_top_tasks(query=objective, k=k)\n","        return self.execution_chain.run(\n","            objective=objective, context=\"\\n\".join(context), task=task\n","        )\n","\n","    def _call(\n","        self,\n","        inputs: Dict[str, Any],\n","        run_manager: Optional[CallbackManagerForChainRun] = None,\n","    ) -> Dict[str, Any]:\n","        \"\"\"Run the agent.\"\"\"\n","        objective = inputs[\"objective\"]\n","        first_task = inputs.get(\"first_task\", \"Make a todo list\")\n","        self.add_task({\"task_id\": 1, \"task_name\": first_task})\n","        num_iters = 0\n","        while True:\n","            if self.task_list:\n","                self.print_task_list()\n","\n","                # Step 1: Pull the first task\n","                task = self.task_list.popleft()\n","                self.print_next_task(task)\n","\n","                # Step 2: Execute the task\n","                result = self.execute_task(objective, task[\"task_name\"])\n","                this_task_id = int(task[\"task_id\"])\n","                self.print_task_result(result)\n","\n","                # Step 3: Store the result in Pinecone\n","                result_id = f\"result_{task['task_id']}\"\n","                self.vectorstore.add_texts(\n","                    texts=[result],\n","                    metadatas=[{\"task\": task[\"task_name\"]}],\n","                    ids=[result_id],\n","                )\n","\n","                # Step 4: Create new tasks and reprioritize task list\n","                new_tasks = self.get_next_task(result, task[\"task_name\"], objective)\n","                for new_task in new_tasks:\n","                    self.task_id_counter += 1\n","                    new_task.update({\"task_id\": self.task_id_counter})\n","                    self.add_task(new_task)\n","                self.task_list = deque(self.prioritize_tasks(this_task_id, objective))\n","            num_iters += 1\n","            if self.max_iterations is not None and num_iters == self.max_iterations:\n","                print(\n","                    \"\\033[91m\\033[1m\" + \"\\n*****TASK ENDING*****\\n\" + \"\\033[0m\\033[0m\"\n","                )\n","                break\n","        return {}\n","\n","    @classmethod\n","    def from_llm(\n","        cls,\n","        llm: BaseLanguageModel,\n","        vectorstore: VectorStore,\n","        verbose: bool = False,\n","        task_execution_chain: Optional[Chain] = None,\n","        **kwargs: Dict[str, Any],\n","    ) -> \"BabyAGI\":\n","        \"\"\"Initialize the BabyAGI Controller.\"\"\"\n","        task_creation_chain = TaskCreationChain.from_llm(llm, verbose=verbose)\n","        task_prioritization_chain = TaskPrioritizationChain.from_llm(\n","            llm, verbose=verbose\n","        )\n","        if task_execution_chain is None:\n","            execution_chain: Chain = TaskExecutionChain.from_llm(llm, verbose=verbose)\n","        else:\n","            execution_chain = task_execution_chain\n","        return cls(\n","            task_creation_chain=task_creation_chain,\n","            task_prioritization_chain=task_prioritization_chain,\n","            execution_chain=execution_chain,\n","            vectorstore=vectorstore,\n","            **kwargs,\n","        )"],"metadata":{"id":"HnnnNAfXosV9"},"execution_count":null,"outputs":[]}]}