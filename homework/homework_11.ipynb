{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNVrpMYtU75bC0CiclV0YIn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# HW11: Retrieval-augmented LM for QA\n","In the lecture and notebook we learn that LLMs can become stronger when it is granted with retrieval (i.e., context for text execution) and elaborate prompt designing.\n","\n","In this homework, we will make a Question-answering system using context retrieval + text-ada-001 (the Cheapest OpenAI GPT-3 checkpoint, which I believe would be affordable by the free budget of OpenAI account)\n","\n","If it's impossible for you to make any OpenAI API call, you can also finish the assignment without executing the code."],"metadata":{"id":"NZVYaLLyrXVx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VX66-fy2rKaP"},"outputs":[],"source":["#!pip install langchain openai faiss-cpu wikipedia tiktoken"]},{"cell_type":"markdown","source":["### Set Your OpenAI Key"],"metadata":{"id":"erjk-T_8JxRX"}},{"cell_type":"code","source":["import os\n","os.environ[\"OPENAI_API_KEY\"] = \"sk-xxx\""],"metadata":{"id":"SqQUOc5PJ0t3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Gather the context for question answering."],"metadata":{"id":"4hKIWlwcHMDx"}},{"cell_type":"code","source":["import wikipedia\n","\n","wikipedia.set_lang('en')\n","page = wikipedia.page(\"Python (programming language)\")\n","content = page.content"],"metadata":{"id":"zuYHSly-Dade"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The context contains 8485 tokens, which is too long to fit in text-ada-001. Therefore, we need to retrieve the most related information for question answering."],"metadata":{"id":"2OIdn8AmHS0v"}},{"cell_type":"code","source":["import tiktoken\n","\n","enc = tiktoken.encoding_for_model(\"text-ada-001\")\n","\n","len(enc.encode(content))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-qXOGkHkEXFH","executionInfo":{"status":"ok","timestamp":1684771155258,"user_tz":-120,"elapsed":270,"user":{"displayName":"Jingwei Ni","userId":"14293482943107053262"}},"outputId":"eaee69c0-9cdd-4c91-eaba-ce6c75bda00f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8485"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["### TODO 1: Split the context into chunks of 100-character length. Then store them in FAISS using OpenAI embedding model."],"metadata":{"id":"9BLZMSKQIs-f"}},{"cell_type":"code","source":["from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.vectorstores import FAISS\n","from langchain.llms import OpenAI\n","\n","# TODO: Split the context into chunks of 100-character length. Then store them in FAISS using OpenAI embedding model.\n","# Hint: use the above imported tools\n","# Hint: refer to https://python.langchain.com/en/latest/modules/indexes/getting_started.html for the document of textsplitters, vectorstores, and retrievers\n"],"metadata":{"id":"BgV_68rgHd7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"Who invented Python?\"\n","\n","# retrieve useful information for QA using the retriever you obtained.\n","docs = retriever.get_relevant_documents(question)\n","context = \"\\n\".join([doc.page_content for doc in docs])"],"metadata":{"id":"rfskQcr5Jdtf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### TODO 2: question answering using retrieved context and OpenAI call."],"metadata":{"id":"lf76m8qi2f4A"}},{"cell_type":"code","source":["qa_prompt = \"\"\"Given the context: {context}\n","The answer to \"{question}\" is:\"\"\"\n","model_name = 'text-ada-001'\n","\n","# TODO 2: question answering using retrieved context and OpenAI call.\n"],"metadata":{"id":"McG3l0akJ_uI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Ip27rVd8L_f5","executionInfo":{"status":"ok","timestamp":1684771423234,"user_tz":-120,"elapsed":232,"user":{"displayName":"Jingwei Ni","userId":"14293482943107053262"}},"outputId":"2b3b5f52-427f-4a82-a254-6a6500b3b6a2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' Guido van Rossum.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":43}]}]}